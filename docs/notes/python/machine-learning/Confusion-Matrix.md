---
title: 混淆矩阵
createTime: 2025/02/04 20:05:27
permalink: /python/lp5810au/
---
# 混淆矩阵示例

混淆矩阵（Confusion Matrix）是评估分类模型性能的工具，展示了预测结果与实际结果的对比。它通常用于二分类问题，但也可扩展到多分类。

## 混淆矩阵的结构

一个二分类问题的混淆矩阵如下：
- T：代表你是预测成功还是失败
- P/N：代表预测的是正例还是负例

|                     | 实际为正例 | 实际为负例 |
|---------------------|------------|------------|
| **预测为正例**      | TP (真正例) | FP (假正例) |
| **预测为负例**      | FN (假负例) | TN (真负例) |

- **TP (True Positive)**: 实际为正例，预测为正例。
- **FP (False Positive)**: 实际为负例，预测为正例。
- **FN (False Negative)**: 实际为正例，预测为负例。
- **TN (True Negative)**: 实际为负例，预测为负例。

## 示例

假设有一个二分类模型，用于预测患者是否患有某种疾病。以下是模型的预测结果：

- 实际患病人数：100
- 实际健康人数：200
- 模型预测患病人数：90（其中80人正确预测，10人错误预测）
- 模型预测健康人数：210（其中190人正确预测，20人错误预测）

对应的混淆矩阵如下：

|                     | 实际患病 | 实际健康 |
|---------------------|----------|----------|
| **预测患病**        | 80 (TP)  | 10 (FP)  |
| **预测健康**        | 20 (FN)  | 190 (TN) |

## 常用指标

基于混淆矩阵，可以计算以下指标：

- **准确率 (Accuracy)**: (TP + TN) / (TP + FP + FN + TN)
- **精确率 (Precision)**: TP / (TP + FP)
- **召回率 (Recall)**: TP / (TP + FN)
- **F1分数 (F1 Score)**: 

$$ \frac{2 \cdot Precision \cdot Recall}{Precision + Recall}$$

>[!tip]
> 精确率: 预测正确的正例的样本数 / 预测的正例的样本数
> 
> 召回率: 预测正确的正例的样本数 / 实际的正例的样本数